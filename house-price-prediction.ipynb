{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:06:22.674381Z","iopub.execute_input":"2021-12-19T09:06:22.674633Z","iopub.status.idle":"2021-12-19T09:06:22.683585Z","shell.execute_reply.started":"2021-12-19T09:06:22.674606Z","shell.execute_reply":"2021-12-19T09:06:22.682831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:07:20.060203Z","iopub.execute_input":"2021-12-19T09:07:20.060452Z","iopub.status.idle":"2021-12-19T09:07:20.109393Z","shell.execute_reply.started":"2021-12-19T09:07:20.060425Z","shell.execute_reply":"2021-12-19T09:07:20.108457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:07:17.29002Z","iopub.execute_input":"2021-12-19T09:07:17.290324Z","iopub.status.idle":"2021-12-19T09:07:17.298295Z","shell.execute_reply.started":"2021-12-19T09:07:17.290291Z","shell.execute_reply":"2021-12-19T09:07:17.297444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:07:25.701023Z","iopub.execute_input":"2021-12-19T09:07:25.701344Z","iopub.status.idle":"2021-12-19T09:07:25.736876Z","shell.execute_reply.started":"2021-12-19T09:07:25.701306Z","shell.execute_reply":"2021-12-19T09:07:25.736041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:07:36.183119Z","iopub.execute_input":"2021-12-19T09:07:36.183894Z","iopub.status.idle":"2021-12-19T09:07:36.207704Z","shell.execute_reply.started":"2021-12-19T09:07:36.18384Z","shell.execute_reply":"2021-12-19T09:07:36.206887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Ok so there are total of 81 columns, that's hell lot of variables.","metadata":{}},{"cell_type":"code","source":"train.count()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:28:44.222129Z","iopub.execute_input":"2021-12-18T06:28:44.222444Z","iopub.status.idle":"2021-12-18T06:28:44.243813Z","shell.execute_reply.started":"2021-12-18T06:28:44.222412Z","shell.execute_reply":"2021-12-18T06:28:44.242749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## Starting preliminary analysis of data","metadata":{}},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:26:15.677501Z","iopub.execute_input":"2021-12-19T09:26:15.678327Z","iopub.status.idle":"2021-12-19T09:26:15.686908Z","shell.execute_reply.started":"2021-12-19T09:26:15.678283Z","shell.execute_reply":"2021-12-19T09:26:15.68604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe(include = \"all\")","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:26:20.535772Z","iopub.execute_input":"2021-12-19T09:26:20.536047Z","iopub.status.idle":"2021-12-19T09:26:20.717112Z","shell.execute_reply.started":"2021-12-19T09:26:20.53601Z","shell.execute_reply":"2021-12-19T09:26:20.716224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:26:44.379399Z","iopub.execute_input":"2021-12-19T09:26:44.379694Z","iopub.status.idle":"2021-12-19T09:26:44.405864Z","shell.execute_reply.started":"2021-12-19T09:26:44.379664Z","shell.execute_reply":"2021-12-19T09:26:44.405064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This gave us small gist about the dataset","metadata":{}},{"cell_type":"markdown","source":"> ## Identifying and dealing with Missing values","metadata":{}},{"cell_type":"code","source":"train.isnull()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:27:51.301817Z","iopub.execute_input":"2021-12-19T09:27:51.302352Z","iopub.status.idle":"2021-12-19T09:27:51.343078Z","shell.execute_reply.started":"2021-12-19T09:27:51.302319Z","shell.execute_reply":"2021-12-19T09:27:51.342354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### I can see there are too many True values, hence missing values.","metadata":{}},{"cell_type":"code","source":"#To count how many missing values are there in the dataset in row as well as column\ntrain.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:28:13.325538Z","iopub.execute_input":"2021-12-19T09:28:13.325809Z","iopub.status.idle":"2021-12-19T09:28:13.340742Z","shell.execute_reply.started":"2021-12-19T09:28:13.325781Z","shell.execute_reply":"2021-12-19T09:28:13.339941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:28:18.910141Z","iopub.execute_input":"2021-12-19T09:28:18.910998Z","iopub.status.idle":"2021-12-19T09:28:18.924434Z","shell.execute_reply.started":"2021-12-19T09:28:18.910959Z","shell.execute_reply":"2021-12-19T09:28:18.923888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**##### Oh damn so there are 6965 and 7000 null values**\n##### Let's see null values in each column","metadata":{}},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:28:32.07886Z","iopub.execute_input":"2021-12-19T09:28:32.079663Z","iopub.status.idle":"2021-12-19T09:28:32.094166Z","shell.execute_reply.started":"2021-12-19T09:28:32.079627Z","shell.execute_reply":"2021-12-19T09:28:32.093534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### As there are 81 columns, it's difficult to display all the columns, let's try to display only those columns which have null values.","metadata":{}},{"cell_type":"markdown","source":"### Now before proceeding forward, let's append train and test data so that we can deal with them together.\n##### Before appending them, adding a column named 'type' to distinguish between train and  test data.","metadata":{}},{"cell_type":"code","source":"#Split the train into x_train and y_train so that SalePrice can be kept separate for training later\ny = train.SalePrice\nX = train.drop(columns=[\"SalePrice\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:28:57.602017Z","iopub.execute_input":"2021-12-19T09:28:57.602339Z","iopub.status.idle":"2021-12-19T09:28:57.610036Z","shell.execute_reply.started":"2021-12-19T09:28:57.602305Z","shell.execute_reply":"2021-12-19T09:28:57.609236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape, X.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:29:00.000673Z","iopub.execute_input":"2021-12-19T09:29:00.000956Z","iopub.status.idle":"2021-12-19T09:29:00.0075Z","shell.execute_reply.started":"2021-12-19T09:29:00.000926Z","shell.execute_reply":"2021-12-19T09:29:00.006546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"X['Type'] = 'train'\ntest['Type'] = 'test'\n#test['SalePrice'] = -1\ndata = X.append(test)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:29:58.903299Z","iopub.execute_input":"2021-12-19T09:29:58.90356Z","iopub.status.idle":"2021-12-19T09:29:58.926448Z","shell.execute_reply.started":"2021-12-19T09:29:58.903532Z","shell.execute_reply":"2021-12-19T09:29:58.925574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:30:49.23836Z","iopub.execute_input":"2021-12-19T09:30:49.238623Z","iopub.status.idle":"2021-12-19T09:30:49.264631Z","shell.execute_reply.started":"2021-12-19T09:30:49.238595Z","shell.execute_reply":"2021-12-19T09:30:49.263843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:30:51.694035Z","iopub.execute_input":"2021-12-19T09:30:51.694331Z","iopub.status.idle":"2021-12-19T09:30:51.720886Z","shell.execute_reply.started":"2021-12-19T09:30:51.6943Z","shell.execute_reply":"2021-12-19T09:30:51.719954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**##### So now, 6965 + 7000 = 13965 null values are there in total**\n##### Now as said above, let's find out specific columns which are having null values.","metadata":{}},{"cell_type":"code","source":"columns_having_null_values = data[data.columns[data.isnull().sum()>0]]\ncolumns_having_null_values","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:47:17.138937Z","iopub.execute_input":"2021-12-19T09:47:17.139208Z","iopub.status.idle":"2021-12-19T09:47:17.200755Z","shell.execute_reply.started":"2021-12-19T09:47:17.139179Z","shell.execute_reply":"2021-12-19T09:47:17.200046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**##### Now we have a figure that 34 columns have null values out of 81 columns. This made our task much easier than before.**","metadata":{}},{"cell_type":"markdown","source":"## Now comes the most tidius part to deal with missing values","metadata":{}},{"cell_type":"code","source":"# We have to check what values are there in the table so that we can fill values according to real world scenario.\ndata['Electrical'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:47:25.746683Z","iopub.execute_input":"2021-12-19T09:47:25.747424Z","iopub.status.idle":"2021-12-19T09:47:25.756838Z","shell.execute_reply.started":"2021-12-19T09:47:25.747378Z","shell.execute_reply":"2021-12-19T09:47:25.756109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### In the above values, we can see that \"Sbrkr\" is the mostly used 'Electrical' part. Here we can't put \"None\" in the null values because a house must have \"Electrical\" items/fuses. So we will fill null values with \"Sbrkr\" in this column.","metadata":{}},{"cell_type":"code","source":"data['Electrical'].fillna(\"Sbrkr\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:48:58.960833Z","iopub.execute_input":"2021-12-19T09:48:58.961099Z","iopub.status.idle":"2021-12-19T09:48:58.966679Z","shell.execute_reply.started":"2021-12-19T09:48:58.961071Z","shell.execute_reply":"2021-12-19T09:48:58.965726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Now we have to do this task for each columns with null/nan values (that's why I mentioned it as a tidius part).","metadata":{}},{"cell_type":"code","source":"data['MSZoning'].value_counts()\n#Filling null values with 'RL'\ndata['MSZoning'].fillna(\"RL\",inplace=True)\n\n#Filling nul values with mean\ndata['LotFrontage'].fillna(data['LotFrontage'].mean(), inplace=True)\n\ndata['Alley'].fillna(\"Nothing\", inplace=True)\ndata['Utilities'].fillna(\"AllPub\", inplace=True)\ndata['Exterior1st'].fillna(\"VinylSd\", inplace=True)\ndata['Exterior2nd'].fillna(\"VinylSd\", inplace=True)\ndata['MasVnrArea'].fillna(0, inplace=True)\ndata['MasVnrType'].fillna(\"None\", inplace=True)\ndata['BsmtCond'].fillna(\"No\", inplace=True)\ndata['BsmtExposure'].fillna(\"NB\", inplace=True)\ndata['BsmtFinType1'].fillna(\"NB\", inplace=True)\ndata['BsmtFinSF1'].fillna(0.0, inplace=True)\ndata['BsmtFinSF2'].fillna(0.0, inplace=True)\ndata['BsmtUnfSF'].fillna(0.0, inplace=True)\ndata['TotalBsmtSF'].fillna(0.0, inplace=True)\ndata['BsmtFullBath'].fillna(0.0, inplace=True)\ndata['BsmtHalfBath'].fillna(0.0, inplace=True)\ndata['KitchenQual'].fillna(\"TA\", inplace=True)\ndata['Functional'].fillna(\"Typ\", inplace=True)\ndata['FireplaceQu'].fillna(\"None\", inplace=True)\ndata['GarageType'].fillna(\"No\", inplace=True)\ndata['GarageYrBlt'].fillna(0, inplace=True)\ndata['GarageFinish'].fillna(\"No\", inplace=True)\ndata['GarageCars'].fillna(0, inplace=True)\ndata['GarageArea'].fillna(0, inplace=True)\ndata['GarageQual'].fillna(\"No\", inplace=True)\ndata['GarageCond'].fillna(\"No\", inplace=True)\ndata['PoolQC'].fillna(\"No\", inplace=True)\ndata['Fence'].fillna(\"No\", inplace=True)\ndata['MiscFeature'].fillna(\"No\", inplace=True)\ndata['SaleType'].fillna(\"Con\", inplace=True)\ndata['SaleCondition'].fillna(\"None\", inplace=True)\ndata['BsmtQual'].fillna(\"TA\", inplace=True)\ndata['BsmtFinType2'].fillna(\"Unf\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:49:44.001954Z","iopub.execute_input":"2021-12-19T09:49:44.002518Z","iopub.status.idle":"2021-12-19T09:49:44.04097Z","shell.execute_reply.started":"2021-12-19T09:49:44.002469Z","shell.execute_reply":"2021-12-19T09:49:44.040287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Now let's see what is the number of null values.","metadata":{}},{"cell_type":"code","source":"data.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:49:52.537768Z","iopub.execute_input":"2021-12-19T09:49:52.53834Z","iopub.status.idle":"2021-12-19T09:49:52.562501Z","shell.execute_reply.started":"2021-12-19T09:49:52.538289Z","shell.execute_reply":"2021-12-19T09:49:52.561626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ##we have treated all the null values.","metadata":{}},{"cell_type":"markdown","source":"##### Let's deal with different types of data types in the dataset","metadata":{}},{"cell_type":"code","source":"int_columns = data[data.columns[data.dtypes=='int']]\nint_columns.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:50:05.338166Z","iopub.execute_input":"2021-12-19T09:50:05.338443Z","iopub.status.idle":"2021-12-19T09:50:05.348849Z","shell.execute_reply.started":"2021-12-19T09:50:05.338413Z","shell.execute_reply":"2021-12-19T09:50:05.347936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['MSZoning'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:50:14.744473Z","iopub.execute_input":"2021-12-19T09:50:14.744741Z","iopub.status.idle":"2021-12-19T09:50:14.753149Z","shell.execute_reply.started":"2021-12-19T09:50:14.744711Z","shell.execute_reply":"2021-12-19T09:50:14.752537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"object_columnns = data[data.columns[data.dtypes=='object']]\nobject_columnns.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:50:25.360278Z","iopub.execute_input":"2021-12-19T09:50:25.361111Z","iopub.status.idle":"2021-12-19T09:50:25.371023Z","shell.execute_reply.started":"2021-12-19T09:50:25.361075Z","shell.execute_reply":"2021-12-19T09:50:25.37018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"float_columns = data[data.columns[data.dtypes=='float']]\nfloat_columns.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:50:29.203265Z","iopub.execute_input":"2021-12-19T09:50:29.20406Z","iopub.status.idle":"2021-12-19T09:50:29.21086Z","shell.execute_reply.started":"2021-12-19T09:50:29.204026Z","shell.execute_reply":"2021-12-19T09:50:29.210318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## Label Encoding the categorical variables","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfor i in object_columnns:\n    label = LabelEncoder()\n    label.fit(data[i].values)\n    data[i] = label.transform(data[i].values)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:24.638251Z","iopub.execute_input":"2021-12-19T09:51:24.638674Z","iopub.status.idle":"2021-12-19T09:51:24.643219Z","shell.execute_reply.started":"2021-12-19T09:51:24.638631Z","shell.execute_reply":"2021-12-19T09:51:24.642451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"object_columnns = data[data.columns[data.dtypes=='object']]\nobject_columnns.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:27.489231Z","iopub.execute_input":"2021-12-19T09:51:27.489507Z","iopub.status.idle":"2021-12-19T09:51:27.496306Z","shell.execute_reply.started":"2021-12-19T09:51:27.489477Z","shell.execute_reply":"2021-12-19T09:51:27.495761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"int_columns = data[data.columns[data.dtypes=='int']]\nint_columns.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:28.991194Z","iopub.execute_input":"2021-12-19T09:51:28.991453Z","iopub.status.idle":"2021-12-19T09:51:28.999821Z","shell.execute_reply.started":"2021-12-19T09:51:28.991425Z","shell.execute_reply":"2021-12-19T09:51:28.998869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:33.11174Z","iopub.execute_input":"2021-12-19T09:51:33.112391Z","iopub.status.idle":"2021-12-19T09:51:33.131807Z","shell.execute_reply.started":"2021-12-19T09:51:33.112354Z","shell.execute_reply":"2021-12-19T09:51:33.131205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### So now we can see that all the object columns are turned to int\n#### Let's split back the train and test data ","metadata":{}},{"cell_type":"code","source":"X_ = data[data.Type==1]\nX_ = X_.drop([\"Type\"], axis=1)\n\ntest_ = data[data.Type==0]\ntest_ = test_.drop([\"Type\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:00:33.254579Z","iopub.execute_input":"2021-12-19T10:00:33.254881Z","iopub.status.idle":"2021-12-19T10:00:33.264989Z","shell.execute_reply.started":"2021-12-19T10:00:33.254849Z","shell.execute_reply":"2021-12-19T10:00:33.264161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_.shape, y.shape, test_.shape ","metadata":{"execution":{"iopub.status.busy":"2021-12-16T06:59:45.458638Z","iopub.execute_input":"2021-12-16T06:59:45.459451Z","iopub.status.idle":"2021-12-16T06:59:45.469064Z","shell.execute_reply.started":"2021-12-16T06:59:45.459418Z","shell.execute_reply":"2021-12-16T06:59:45.468081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scaling\n##### It is required because dataset has columns which varies highly in magnitudes. If scaling is not performed then high magnitude values will have more impact on modelling.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nminmaxscaler = MinMaxScaler()\nx_scaled = minmaxscaler.fit_transform(X_)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:00:38.036666Z","iopub.execute_input":"2021-12-19T10:00:38.037381Z","iopub.status.idle":"2021-12-19T10:00:38.048384Z","shell.execute_reply.started":"2021-12-19T10:00:38.037343Z","shell.execute_reply":"2021-12-19T10:00:38.047569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We can do Scaling directly with formula but we have pre-defined libraries so we will use them.. \nx_scaled_formula = X_.copy()\nfor cols in x_scaled_formula.columns:\n    x_scaled_formula[cols] = x_scaled_formula[cols] / x_scaled_formula[cols].abs().max()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:00:40.693163Z","iopub.execute_input":"2021-12-19T10:00:40.693448Z","iopub.status.idle":"2021-12-19T10:00:40.743808Z","shell.execute_reply.started":"2021-12-19T10:00:40.693415Z","shell.execute_reply":"2021-12-19T10:00:40.743186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_scaled_formula.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:00:45.31476Z","iopub.execute_input":"2021-12-19T10:00:45.315356Z","iopub.status.idle":"2021-12-19T10:00:45.349737Z","shell.execute_reply.started":"2021-12-19T10:00:45.315322Z","shell.execute_reply":"2021-12-19T10:00:45.348712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## Modelling aka ML\n##### There are so many regression algorithms which we can use, so we need to use most of them and then find out the best out of them.","metadata":{}},{"cell_type":"markdown","source":"##### Let's do the train_test_split first","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X_, y, test_size=0.25, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:00:50.64757Z","iopub.execute_input":"2021-12-19T10:00:50.647831Z","iopub.status.idle":"2021-12-19T10:00:50.705304Z","shell.execute_reply.started":"2021-12-19T10:00:50.647804Z","shell.execute_reply":"2021-12-19T10:00:50.704567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ###  Random Forest Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nmodel_randomforest = RandomForestRegressor(n_estimators=500, n_jobs=-1, random_state=13)\nmodel_randomforest.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:00:54.691063Z","iopub.execute_input":"2021-12-19T10:00:54.691911Z","iopub.status.idle":"2021-12-19T10:00:58.761537Z","shell.execute_reply.started":"2021-12-19T10:00:54.691841Z","shell.execute_reply":"2021-12-19T10:00:58.760654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predict_randomforest = model_randomforest.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:00:58.873032Z","iopub.execute_input":"2021-12-19T10:00:58.873877Z","iopub.status.idle":"2021-12-19T10:00:58.982494Z","shell.execute_reply.started":"2021-12-19T10:00:58.873835Z","shell.execute_reply":"2021-12-19T10:00:58.981672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_randomforest.score(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:01:02.647205Z","iopub.execute_input":"2021-12-19T10:01:02.647492Z","iopub.status.idle":"2021-12-19T10:01:02.759579Z","shell.execute_reply.started":"2021-12-19T10:01:02.64746Z","shell.execute_reply":"2021-12-19T10:01:02.758781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ### XGBoost","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nmodel_xgboost = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\n \nmodel_xgboost.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:01:06.575859Z","iopub.execute_input":"2021-12-19T10:01:06.576144Z","iopub.status.idle":"2021-12-19T10:01:14.172904Z","shell.execute_reply.started":"2021-12-19T10:01:06.576105Z","shell.execute_reply":"2021-12-19T10:01:14.172088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_xgboost.score(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:01:14.480868Z","iopub.execute_input":"2021-12-19T10:01:14.481169Z","iopub.status.idle":"2021-12-19T10:01:14.512646Z","shell.execute_reply.started":"2021-12-19T10:01:14.48112Z","shell.execute_reply":"2021-12-19T10:01:14.51203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_xgboost.score(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:01:16.87196Z","iopub.execute_input":"2021-12-19T10:01:16.872702Z","iopub.status.idle":"2021-12-19T10:01:16.894567Z","shell.execute_reply.started":"2021-12-19T10:01:16.87266Z","shell.execute_reply":"2021-12-19T10:01:16.893845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predict_xgb = model_xgboost.predict(test_)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:01:34.458753Z","iopub.execute_input":"2021-12-19T10:01:34.459365Z","iopub.status.idle":"2021-12-19T10:01:34.48882Z","shell.execute_reply.started":"2021-12-19T10:01:34.459324Z","shell.execute_reply":"2021-12-19T10:01:34.488093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Let's try to submit the submission first.","metadata":{}},{"cell_type":"code","source":"result = pd.DataFrame()\nresult['Id'] = test['Id']\nresult['SalePrice'] = y_predict_xgb","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:01:38.539668Z","iopub.execute_input":"2021-12-19T10:01:38.539962Z","iopub.status.idle":"2021-12-19T10:01:38.547326Z","shell.execute_reply.started":"2021-12-19T10:01:38.53993Z","shell.execute_reply":"2021-12-19T10:01:38.546552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:01:41.082877Z","iopub.execute_input":"2021-12-19T10:01:41.083376Z","iopub.status.idle":"2021-12-19T10:01:41.091736Z","shell.execute_reply.started":"2021-12-19T10:01:41.083344Z","shell.execute_reply":"2021-12-19T10:01:41.090913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}